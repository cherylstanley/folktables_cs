{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run code on Anaconda Env.\n",
    "# Construct data source by downloading 2018 data\n",
    "import folktables\n",
    "from folktables import ACSDataSource, ACSIncome\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)  # have to use 'download=True' if data not already avaiable locally\n",
    "\n",
    "features, label, group = ACSIncome.df_to_numpy(acs_data)  # split data into corresponding features, labels, and group\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixRaceRates(data, target_bhn_ratio):\n",
    "    # Input: complete training dataset as numpy array\n",
    "    # Output: filtered dataset where ratio of bhn indiviudals satisfies the desired target (+/- 1%)\n",
    "    # RAC1P column # for ASCIncome task -> 9\n",
    "\n",
    "    # count occurances of BHN in the RAC1P column\n",
    "    rac1p_values = data[:, 9]\n",
    "    bhn_count = np.count_nonzero(rac1p_values == 2) + np.count_nonzero(rac1p_values == 3)\n",
    "    \n",
    "    # calc current ratio\n",
    "    current_ratio = bhn_count / len(rac1p_values)\n",
    "\n",
    "    # if the current ratio is within 5% of desired ratio, return the dataset\n",
    "    if abs(current_ratio - target_bhn_ratio) < 0.01:\n",
    "        return data\n",
    "\n",
    "    # if current ratio > target ratio: remove bhn rows\n",
    "    if current_ratio > target_bhn_ratio:\n",
    "        # find indicies of bhn\n",
    "        target_indicies = np.where((rac1p_values == 2) | (rac1p_values == 3))[0]\n",
    "        np.random.shuffle(target_indicies)\n",
    "        # calculate num of bhn rows to remove, then remove specified # of bhn rows\n",
    "        remove_count = bhn_count - int(target_bhn_ratio * len(rac1p_values))\n",
    "        data = np.delete(data, target_indicies[:remove_count], axis=0)\n",
    "    else: \n",
    "    # current ratio < target ratio: remove non-bhn rows\n",
    "        # find indicies of non-bhn\n",
    "        target_indicies = np.where((rac1p_values != 2) & (rac1p_values != 3))[0]\n",
    "        np.random.shuffle(target_indicies)\n",
    "        # calculate num of non-bhn rows to remove, then remove specified # of non-bhn rows\n",
    "        non_bhn_count = len(rac1p_values) - (np.count_nonzero(rac1p_values == 2) + np.count_nonzero(rac1p_values == 3))\n",
    "        remove_count = non_bhn_count - int((1-target_bhn_ratio) * len(rac1p_values))\n",
    "        data = np.delete(data, target_indicies[:remove_count], axis=0)\n",
    "        \n",
    "    # recalc current ratio\n",
    "    '''\n",
    "    rac1p_values = data[:, 9]\n",
    "    bhn_count = np.count_nonzero(rac1p_values == 2) + np.count_nonzero(rac1p_values == 3)\n",
    "    current_ratio = bhn_count / len(rac1p_values)\n",
    "    print(\"updated ratio: \", current_ratio)\n",
    "    '''\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(pred, label):\n",
    "    tn, fp, fn, tp = confusion_matrix(label, pred).ravel()\n",
    "    acc = (tp + tn)/ (tp + tn + fp + fn)\n",
    "    tpr = tp / (tp + fn)\n",
    "    fnr = fn / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "    tnr = tn / (fp + tn)\n",
    "    return [acc, tpr, fnr, fpr, tnr]\n",
    "\n",
    "def evaluateRatio(features, label, group, bhn_ratio):\n",
    "    # randomly split the data into training and testing\n",
    "    # train-test split: 80/20\n",
    "    X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "        features, label, group, test_size=0.2)\n",
    "\n",
    "    # reshape y_train into column vector, then concatenate with X_train to reformat training data\n",
    "    train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "\n",
    "    # filter training data to satisfy desired BHN ratio\n",
    "    modified_train_data = mixRaceRates(train_data, bhn_ratio)\n",
    "    \n",
    "    new_X_train = modified_train_data[:, :-1] # get all cols except for last one\n",
    "    new_y_train = modified_train_data[:, -1]  # get only the last col\n",
    "\n",
    "    # create the pipeline: normalize data, then use logistic regression as classifier\n",
    "    model = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=16, min_samples_leaf=3))\n",
    "    # train the model with the training data\n",
    "    model.fit(new_X_train, new_y_train)\n",
    "\n",
    "    # make predictions on test data set\n",
    "    yhat = model.predict(X_test)\n",
    "\n",
    "    yhat_wa = yhat[(group_test == 1) | (group_test == 6)]  # all rows from prediction where group=1 (white) or group=6 (asian)\n",
    "    yhat_bhn = yhat[(group_test == 2) | (group_test == 3)]  # all rows from prediction where group=2 (black) or group=3 (american indian)\n",
    "\n",
    "    y_test_wa = y_test[(group_test == 1) | (group_test == 6)]  # all rows from test set where group=1 (white) or group=6 (asian)\n",
    "    y_test_bhn = y_test[(group_test == 2) | (group_test == 3)]  # all rows from test set where group=2 (black) or group=3 (american indian)\n",
    "    \n",
    "    # get the acc, tpr, fnr, fpr, tnr data for WA and BHN groups\n",
    "    wa_data = confusion(yhat_wa, y_test_wa)\n",
    "    bhn_data = confusion(yhat_bhn, y_test_bhn)\n",
    "    \n",
    "    return wa_data, bhn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bhn_ratios = [0.05, 0.04, 0.03, 0.02, 0.01, 0]\n",
    "# map: % bhn in training set -> [ACC, TPR, FNR, FPR, TNR]\n",
    "wa_map = {}\n",
    "bhn_map = {}\n",
    "\n",
    "for ratio in target_bhn_ratios:\n",
    "    wa_data, bhn_data = evaluateRatio(features, label, group, ratio)\n",
    "    wa_map[ratio] = wa_data\n",
    "    bhn_map[ratio] = bhn_data\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efcf1752db8516e6a1a861a9a29cd8f0494d7cf6ff0d254dcea6989d66e5bc7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
