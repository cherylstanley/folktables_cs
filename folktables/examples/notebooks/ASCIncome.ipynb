{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothychang/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/timothychang/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for 2018 1-Year person survey for CA...\n"
     ]
    }
   ],
   "source": [
    "# Run code on Anaconda Env.\n",
    "# Construct data source by downloading 2018 data\n",
    "import folktables\n",
    "from folktables import ACSDataSource, ACSIncome\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)  # have to use 'download=True' if data not already avaiable locally\n",
    "\n",
    "features, label, group = ACSIncome.df_to_numpy(acs_data)  # split data into corresponding features, labels, and group\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixRaceRates(data, target_bhn_ratio):\n",
    "    # Input: complete training dataset as numpy array\n",
    "    # Output: filtered dataset where ratio of bhn indiviudals satisfies the desired target (+/- 1%)\n",
    "    # RAC1P column # for ASCIncome task -> 9\n",
    "\n",
    "    # count occurances of BHN in the RAC1P column\n",
    "    rac1p_values = data[:, 9]\n",
    "    bhn_count = np.count_nonzero(rac1p_values == 2) + np.count_nonzero(rac1p_values == 3)\n",
    "    \n",
    "    # calc current ratio\n",
    "    current_ratio = bhn_count / len(rac1p_values)\n",
    "\n",
    "    # if the current ratio is within 5% of desired ratio, return the dataset\n",
    "    if abs(current_ratio - target_bhn_ratio) < 0.01:\n",
    "        print(\"here\")\n",
    "        return data\n",
    "\n",
    "    # if current ratio > target ratio: remove bhn rows\n",
    "    if current_ratio > target_bhn_ratio:\n",
    "        # find indicies of bhn\n",
    "        target_indicies = np.where((rac1p_values == 2) | (rac1p_values == 3))[0]\n",
    "        np.random.shuffle(target_indicies)\n",
    "        # calculate num of bhn rows to remove, then remove specified # of bhn rows\n",
    "        remove_count = bhn_count - int(target_bhn_ratio * len(rac1p_values))\n",
    "        data = np.delete(data, target_indicies[:remove_count], axis=0)\n",
    "    else: \n",
    "    # current ratio < target ratio: remove non-bhn rows\n",
    "        # find indicies of non-bhn\n",
    "        target_indicies = np.where((rac1p_values != 2) & (rac1p_values != 3))[0]\n",
    "        np.random.shuffle(target_indicies)\n",
    "        # calculate num of non-bhn rows to remove, then remove specified # of non-bhn rows\n",
    "        non_bhn_count = len(rac1p_values) - (np.count_nonzero(rac1p_values == 2) + np.count_nonzero(rac1p_values == 3))\n",
    "        remove_count = non_bhn_count - int((1-target_bhn_ratio) * len(rac1p_values))\n",
    "        data = np.delete(data, target_indicies[:remove_count], axis=0)\n",
    "        \n",
    "    # recalc current ratio\n",
    "    '''\n",
    "    rac1p_values = data[:, 9]\n",
    "    bhn_count = np.count_nonzero(rac1p_values == 2) + np.count_nonzero(rac1p_values == 3)\n",
    "    current_ratio = bhn_count / len(rac1p_values)\n",
    "    print(\"updated ratio: \", current_ratio)\n",
    "    '''\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(max_depth=16, min_samples_leaf=3))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly split the data into training and testing\n",
    "# train-test split: 80/20\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features, label, group, test_size=0.2)\n",
    "\n",
    "# reshape y_train into column vector, then concatenate with X_train to reformat training data\n",
    "train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# filter training data to satisfy desired BHN ratio\n",
    "modified_train_data = mixRaceRates(train_data, 0.03)\n",
    "new_X_train = modified_train_data[:, :-1] # get all cols except for last one\n",
    "new_y_train = modified_train_data[:, -1]  # get only the last col\n",
    "\n",
    "# create the pipeline: normalize data, then use logistic regression as classifier\n",
    "model = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=16, min_samples_leaf=3))\n",
    "# train the model with the training data\n",
    "model.fit(new_X_train, new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test data set\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "yhat_wa = yhat[(group_test == 1) | (group_test == 6)]  # all rows from prediction where group=1 (white) or group=6 (asian)\n",
    "yhat_bhn = yhat[(group_test == 2) | (group_test == 3)]  # all rows from prediction where group=2 (black) or group=3 (american indian)\n",
    "\n",
    "y_test_wa = y_test[(group_test == 1) | (group_test == 6)]  # all rows from test set where group=1 (white) or group=6 (asian)\n",
    "y_test_bhn = y_test[(group_test == 2) | (group_test == 3)]  # all rows from test set where group=2 (black) or group=3 (american indian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for WA population:\n",
      "Total Accuracy:  0.8182171169713639\n",
      "Total True Positive Rate:  0.8054704751050644\n",
      "Total False Negative Rate:  0.19452952489493552\n",
      "\n",
      "Metrics for BHN population:\n",
      "Total Accuracy:  0.794102431453699\n",
      "Total True Positive Rate:  0.6793893129770993\n",
      "Total False Negative Rate:  0.32061068702290074\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find tpr, fpr, tnr, fnr with buit-in confusion matrix for binary labels\n",
    "def confusion(pred, label):\n",
    "    tn, fp, fn, tp = confusion_matrix(label, pred).ravel()\n",
    "    print(\"Total Accuracy: \", (tp + tn)/ (tp + tn + fp + fn))\n",
    "    print(\"Total True Positive Rate: \", tp / (tp + fn))\n",
    "    print(\"Total False Negative Rate: \", fn / (tp + fn))\n",
    "\n",
    "print(\"Metrics for WA population:\")\n",
    "confusion(yhat_wa, y_test_wa)\n",
    "print(\"\\nMetrics for BHN population:\")\n",
    "confusion(yhat_bhn, y_test_bhn)\n",
    "\n",
    "#print(\"\\n% dataset WA: \", (np.count_nonzero(group==1) + np.count_nonzero(group==6)) / group.shape[0] * 100)\n",
    "#print(\"% dataset BHN: \", (np.count_nonzero(group==2) + np.count_nonzero(group==3))/ group.shape[0] * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efcf1752db8516e6a1a861a9a29cd8f0494d7cf6ff0d254dcea6989d66e5bc7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
