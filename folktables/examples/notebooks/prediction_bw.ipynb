{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Task: Income Poverty / Male Female "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ACSIncome_categories = {\n",
    "    \"COW\": {\n",
    "        1.0: (\n",
    "            \"Employee of a private for-profit company or\"\n",
    "            \"business, or of an individual, for wages,\"\n",
    "            \"salary, or commissions\"\n",
    "        ),\n",
    "        2.0: (\n",
    "            \"Employee of a private not-for-profit, tax-exempt,\"\n",
    "            \"or charitable organization\"\n",
    "        ),\n",
    "        3.0: \"Local government employee (city, county, etc.)\",\n",
    "        4.0: \"State government employee\",\n",
    "        5.0: \"Federal government employee\",\n",
    "        6.0: (\n",
    "            \"Self-employed in own not incorporated business,\"\n",
    "            \"professional practice, or farm\"\n",
    "        ),\n",
    "        7.0: (\n",
    "            \"Self-employed in own incorporated business,\"\n",
    "            \"professional practice or farm\"\n",
    "        ),\n",
    "        8.0: \"Working without pay in family business or farm\",\n",
    "        9.0: \"Unemployed and last worked 5 years ago or earlier or never worked\",\n",
    "    },\n",
    "    \"SCHL\": {\n",
    "        1.0: \"No schooling completed\",\n",
    "        2.0: \"Nursery school, preschool\",\n",
    "        3.0: \"Kindergarten\",\n",
    "        4.0: \"Grade 1\",\n",
    "        5.0: \"Grade 2\",\n",
    "        6.0: \"Grade 3\",\n",
    "        7.0: \"Grade 4\",\n",
    "        8.0: \"Grade 5\",\n",
    "        9.0: \"Grade 6\",\n",
    "        10.0: \"Grade 7\",\n",
    "        11.0: \"Grade 8\",\n",
    "        12.0: \"Grade 9\",\n",
    "        13.0: \"Grade 10\",\n",
    "        14.0: \"Grade 11\",\n",
    "        15.0: \"12th grade - no diploma\",\n",
    "        16.0: \"Regular high school diploma\",\n",
    "        17.0: \"GED or alternative credential\",\n",
    "        18.0: \"Some college, but less than 1 year\",\n",
    "        19.0: \"1 or more years of college credit, no degree\",\n",
    "        20.0: \"Associate's degree\",\n",
    "        21.0: \"Bachelor's degree\",\n",
    "        22.0: \"Master's degree\",\n",
    "        23.0: \"Professional degree beyond a bachelor's degree\",\n",
    "        24.0: \"Doctorate degree\",\n",
    "    },\n",
    "    \"MAR\": {\n",
    "        1.0: \"Married\",\n",
    "        2.0: \"Widowed\",\n",
    "        3.0: \"Divorced\",\n",
    "        4.0: \"Separated\",\n",
    "        5.0: \"Never married or under 15 years old\",\n",
    "    },\n",
    "    \"SEX\": {1.0: \"Male\", 2.0: \"Female\"},\n",
    "    \"RAC1P\": {\n",
    "        1.0: \"White alone\",\n",
    "        2.0: \"Black or African American alone\",\n",
    "        3.0: \"American Indian alone\",\n",
    "        4.0: \"Alaska Native alone\",\n",
    "        5.0: (\n",
    "            \"American Indian and Alaska Native tribes specified;\"\n",
    "            \"or American Indian or Alaska Native,\"\n",
    "            \"not specified and no other\"\n",
    "        ),\n",
    "        6.0: \"Asian alone\",\n",
    "        7.0: \"Native Hawaiian and Other Pacific Islander alone\",\n",
    "        8.0: \"Some Other Race alone\",\n",
    "        9.0: \"Two or More Races\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# \"\"\"Data source and problem definitions for American Community Survey (ACS) Public Use Microdata Sample (PUMS).\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import folktables\n",
    "\n",
    "ACSIncomePovertyRatio = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'SEX',\n",
    "        'DIS',\n",
    "        'ESP',\n",
    "        'MIG',\n",
    "        'CIT',\n",
    "        'MIL',\n",
    "        'ANC',\n",
    "        'NATIVITY',\n",
    "        'RELP',\n",
    "        'DEAR',\n",
    "        'DEYE',\n",
    "        'DREM',\n",
    "        'RAC1P',\n",
    "        'GCL',\n",
    "        'ESR',\n",
    "        'OCCP',\n",
    "        'WKHP',\n",
    "    ],\n",
    "    target='POVPIP',\n",
    "    target_transform=lambda x: x < 250,\n",
    "    group='RAC1P',\n",
    "    preprocess=lambda x: x,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ACSIncome = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'OCCP',\n",
    "        'POBP',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 50000,    \n",
    "    group='RAC1P',\n",
    "    preprocess=folktables.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import folktables\n",
    "ACSIncomeNew = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'OCCP',\n",
    "        'POBP',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 25000,    \n",
    "    group='SEX',\n",
    "    preprocess=folktables.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group: 'SEX'for MF, prediction task ACSIncomeNew CA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, generate_categories\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
    "\n",
    "from scipy.stats import sem\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# import fairlearn\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import equalized_odds_ratio\n",
    "from fairlearn.metrics import true_positive_rate, false_positive_rate\n",
    "\n",
    "\n",
    "\n",
    "# The ACS data source contains data for all fifty states, each of which has a\n",
    "# slightly different distribution of features and response. This increases the\n",
    "# diversity of environments in which we can evaluate our methods. For instance, we\n",
    "# can generate another `ACSEmployment` task using data from Texas and repeat the\n",
    "# experiment\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_ca = data_source.get_data(states=[\"CA\"], download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ca label, ca_features, ca_group, be able to explain what that value is and what values from 1-8 for example in CA_group\n",
    "# do histogram to understand each specific understanding of what they are\n",
    "# really good understanding of data for data analysis\n",
    "# which features are useful for group label, predictions\n",
    "# nan value because denominator is 0 and group label might not be 1 and 2\n",
    "\n",
    "ca_features, ca_label, ca_group = ACSIncome.df_to_numpy(acs_ca)\n",
    "\n",
    "# X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "#     ca_features, ca_label, ca_group, test_size=0.2, random_state=0)\n",
    "\n",
    "# model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# yhat = model.predict(X_test)\n",
    "\n",
    "\n",
    "                              \n",
    "# # print(len(y_test), len(yhat))\n",
    "# print(ca_features)\n",
    "# print(ca_label)\n",
    "# print(ca_group)\n",
    "pd.DataFrame(ca_group)\n",
    "\n",
    "\n",
    "    \n",
    "#     #library imports\n",
    "# ca_eq_odd_diff = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "# ca_eq_odd_ratio = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "\n",
    "\n",
    "# # print(\"Number of Positive samples for the 'male' group:\", np.sum((y_test == 1) & (group_test == 1)))\n",
    "\n",
    "# # print(\"Number of Positive samples for the 'female' group:\", np.sum((y_test == 1) & (group_test == 2)))\n",
    "\n",
    "\n",
    "# # print(\"Number of Negative samples for the 'male' group:\", np.sum((y_test == 0) & (group_test == 1)))\n",
    "\n",
    "# # print(\"Number of Negative samples for the 'female' group:\", np.sum((y_test == 0) & (group_test == 2)))\n",
    "\n",
    "# m_TP = np.sum((y_test == 1) & (yhat == 1) & (group_test == 1))\n",
    "# m_TN = np.sum((y_test == 0) & (yhat == 0) & (group_test == 1))\n",
    "# m_FP = np.sum((y_test == 0) & (yhat == 1) & (group_test == 1))\n",
    "# m_FN = np.sum((y_test == 1) & (yhat == 0) & (group_test == 1))\n",
    "\n",
    "# f_TP = np.sum((y_test == 1) & (yhat == 1)  & (group_test == 2))\n",
    "# f_TN = np.sum((y_test == 0) & (yhat == 0) & (group_test == 2))\n",
    "# f_FP = np.sum((y_test == 0) & (yhat == 1) & (group_test == 2))\n",
    "# f_FN = np.sum((y_test == 1) & (yhat == 0)  & (group_test == 2))\n",
    "\n",
    "# # TPR = TP / (TP + FN)\n",
    "# male_tnr = m_TN / (m_TN + m_FP)\n",
    "# female_TNR = f_TN / (f_TN + f_FP)\n",
    "\n",
    "\n",
    "# male_FPR = m_FP / (m_FP + m_TN)\n",
    "# female_FPR = f_FP / (f_FP + f_TN)\n",
    "# # FNR = FN / (FN + TP)\n",
    "\n",
    "# # white_fpr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "# # male_fpr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "# # female_fpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "# male_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "# female_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "# male_tnr = 1 - male_fpr\n",
    "# # white_tnr = np.mean(yhat[(y_test == 0) & (group_test == 0)])\n",
    "# # white_tnr = 1- white_fpr\n",
    "# female_tnr = np.mean(yhat[(y_test == 0) & (group_test == 1)])\n",
    "\n",
    "\n",
    "\n",
    "# # fnr = 1- tpr ? (getting nan otherwise)\n",
    "\n",
    "# # TODO: Figure out why empty slice for W partition but not B\n",
    "# # white_fnr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "# male_fnr = 1 - male_tpr  \n",
    "# female_fnr = np.mean(yhat[(y_test == 0) & (group_test == 2)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# # Equality of opportunity violation: 0.0397\n",
    "# ca_equality_violation = male_tpr - female_tpr\n",
    "\n",
    "\n",
    "\n",
    "# true_parity = np.abs(true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) - true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)]))\n",
    "# parity = (true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) + true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)])) / 2\n",
    "\n",
    "# male_accuracy = accuracy_score(y_test[group_test == 1], yhat[group_test == 1])\n",
    "# female_accuracy = accuracy_score(y_test[group_test == 2], yhat[group_test == 2])\n",
    "\n",
    "# print(\"Number of samples for the 'male' group:\", np.sum((group_test == 1)))\n",
    "\n",
    "\n",
    "# print(\"Number of samples for the 'female' group:\", np.sum((group_test == 2)))\n",
    "# print(\"CA Data\")\n",
    "# print(\"Predicting Income By Gender (M/F)\")\n",
    "\n",
    "# data = {\n",
    "#     'Metric': ['Equality Violation', 'Eq Odds Difference', 'Eq Odds Ratio',\n",
    "#                'True Parity', 'Parity',\n",
    "#                '(M-TPR)', '(F-TPR)',\n",
    "#                '(M-TNR)', '(F-TNR)',\n",
    "#                '(M-FPR)', '(F-FPR)',\n",
    "#                '(M-FNR)', '(F-FNR)',\n",
    "#                'Accuracy (Male)', 'Accuracy (Female)'],\n",
    "#     'Value': [ca_equality_violation, ca_eq_odd_diff, ca_eq_odd_ratio,\n",
    "#                true_parity, parity,\n",
    "#                male_tpr, female_tpr, male_tnr, female_tnr, male_fpr, female_fpr, male_fnr, female_fnr,\n",
    "#                male_accuracy, female_accuracy]\n",
    "# }\n",
    "\n",
    "# table_df = pd.DataFrame(data)\n",
    "\n",
    "# # Display the table\n",
    "# print(table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ca_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ca_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group: 'RAC1P'for BW, prediction task ACSIncome TX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, generate_categories\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
    "\n",
    "from scipy.stats import sem\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# import fairlearn\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import equalized_odds_ratio\n",
    "from fairlearn.metrics import true_positive_rate, false_positive_rate\n",
    "\n",
    "\n",
    "\n",
    "# The ACS data source contains data for all fifty states, each of which has a\n",
    "# slightly different distribution of features and response. This increases the\n",
    "# diversity of environments in which we can evaluate our methods. For instance, we\n",
    "# can generate another `ACSEmployment` task using data from Texas and repeat the\n",
    "# experiment\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "\n",
    "\n",
    "acs_tx = data_source.get_data(states=[\"TX\"], download=True)\n",
    "tx_features, tx_label, tx_group = ACSIncome.df_to_numpy(acs_tx)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    tx_features, tx_label, tx_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "\n",
    "                              \n",
    "# print(len(y_test), len(yhat))\n",
    "# print(tx_features)\n",
    "# print(tx_label)\n",
    "# print(tx_group)\n",
    "\n",
    "\n",
    "    \n",
    "    #library imports\n",
    "tx_eq_odd_diff = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "tx_eq_odd_ratio = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "\n",
    "\n",
    "# print(\"Number of samples for the 'white' group:\", np.sum((y_test == 1) & (group_test == 1)))\n",
    "\n",
    "print(\"Number of samples for the 'white' group:\", np.sum((group_test == 1)))\n",
    "\n",
    "# print(\"Number of samples for the 'black' group:\", np.sum((y_test == 1) & (group_test == 2)))\n",
    "\n",
    "print(\"Number of samples for the 'black' group:\", np.sum((group_test == 2)))\n",
    "\n",
    "# white_fpr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "white_fpr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "black_fpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "white_tnr = 1 - white_fpr\n",
    "# white_tnr = np.mean(yhat[(y_test == 0) & (group_test == 0)])\n",
    "# white_tnr = 1- white_fpr\n",
    "black_tnr = np.mean(yhat[(y_test == 0) & (group_test == 1)])\n",
    "\n",
    "\n",
    "\n",
    "# fnr = 1- tpr ? (getting nan otherwise)\n",
    "\n",
    "# TODO: Figure out why empty slice for W partition but not B\n",
    "# white_fnr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "white_fnr = 1 - white_tpr  \n",
    "black_fnr = np.mean(yhat[(y_test == 0) & (group_test == 2)])\n",
    "\n",
    "white_accuracy = accuracy_score(y_test[group_test == 1], yhat[group_test == 1])\n",
    "black_accuracy = accuracy_score(y_test[group_test == 2], yhat[group_test == 2])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Equality of opportunity violation: 0.0397\n",
    "tx_equality_violation = white_tpr - black_tpr\n",
    "\n",
    "\n",
    "\n",
    "true_parity = np.abs(true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) - true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)]))\n",
    "parity = (true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) + true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)])) / 2\n",
    "\n",
    "\n",
    "print(\"Texas Data\")\n",
    "print(\"Predicting Income By Race (B/W)\")\n",
    "data = {\n",
    "    'Metric': ['Equality Violation', 'Eq Odds Difference', 'Eq Odds Ratio',\n",
    "               'True Parity', 'Parity',\n",
    "               '(W-TPR)', '(B-TPR)',\n",
    "               '(W-TNR)', '(B-TNR)',\n",
    "               '(W-FPR)', '(B-FPR)',\n",
    "               '(W-FNR)', '(B-FNR)',\n",
    "               'Accuracy (White)', 'Accuracy (Black)'],\n",
    "    'Value': [tx_equality_violation, tx_eq_odd_diff, tx_eq_odd_ratio,\n",
    "               true_parity, parity,\n",
    "               white_tpr, black_tpr, white_tnr, black_tnr, white_fpr, black_fpr, white_fnr, black_fnr,\n",
    "               white_accuracy, black_accuracy]\n",
    "}\n",
    "table_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(table_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group: 'RAC1P'for BW, prediction task ACSIncomePovertyRatio TX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, generate_categories\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.stats import sem\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# import fairlearn\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import equalized_odds_ratio\n",
    "from fairlearn.metrics import true_positive_rate, false_positive_rate\n",
    "\n",
    "\n",
    "\n",
    "# The ACS data source contains data for all fifty states, each of which has a\n",
    "# slightly different distribution of features and response. This increases the\n",
    "# diversity of environments in which we can evaluate our methods. For instance, we\n",
    "# can generate another `ACSEmployment` task using data from Texas and repeat the\n",
    "# experiment\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "\n",
    "\n",
    "acs_tx = data_source.get_data(states=[\"TX\"], download=True)\n",
    "tx_features, tx_label, tx_group = ACSIncomePovertyRatio.df_to_numpy(acs_tx)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    tx_features, tx_label, tx_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "\n",
    "                              \n",
    "# print(len(y_test), len(yhat))\n",
    "# print(tx_features)\n",
    "# print(tx_label)\n",
    "# print(tx_group)\n",
    "\n",
    "\n",
    "    \n",
    "    #library imports\n",
    "tx_eq_odd_diff = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "tx_eq_odd_ratio = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "\n",
    "\n",
    "# print(\"Number of samples for the 'white' group:\", np.sum((y_test == 1) & (group_test == 1)))\n",
    "\n",
    "print(\"Number of samples for the 'white' group:\", np.sum((group_test == 1)))\n",
    "\n",
    "# print(\"Number of samples for the 'black' group:\", np.sum((y_test == 1) & (group_test == 2)))\n",
    "\n",
    "print(\"Number of samples for the 'black' group:\", np.sum((group_test == 2)))\n",
    "\n",
    "# white_fpr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "# white_fpr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "# white_fpr, w_tpr, w_thresholds = metrics.roc_curve(y_test, , pos_label=2)\n",
    "\n",
    "black_fpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "white_tnr = 1 - white_fpr\n",
    "# white_tnr = np.mean(yhat[(y_test == 0) & (group_test == 0)])\n",
    "# white_tnr = 1- white_fpr\n",
    "black_tnr = np.mean(yhat[(y_test == 0) & (group_test == 1)])\n",
    "\n",
    "\n",
    "\n",
    "# fnr = 1- tpr ? (getting nan otherwise)\n",
    "\n",
    "# TODO: Figure out why empty slice for W partition but not B / and M not F??)\n",
    "# white_fnr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "white_fnr = 1 - white_tpr  \n",
    "black_fnr = np.mean(yhat[(y_test == 0) & (group_test == 2)])\n",
    "\n",
    "white_accuracy = accuracy_score(y_test[group_test == 1], yhat[group_test == 1])\n",
    "black_accuracy = accuracy_score(y_test[group_test == 2], yhat[group_test == 2])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Equality of opportunity violation: 0.0397\n",
    "tx_equality_violation = white_tpr - black_tpr\n",
    "\n",
    "\n",
    "\n",
    "true_parity = np.abs(true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) - true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)]))\n",
    "parity = (true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) + true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)])) / 2\n",
    "\n",
    "\n",
    "print(\"Texas Data\")\n",
    "print(\"Predicting Income By Race (B/W)\")\n",
    "data = {\n",
    "    'Metric': ['Equality Violation', 'Eq Odds Difference', 'Eq Odds Ratio',\n",
    "               'True Parity', 'Parity',\n",
    "               '(W-TPR)', '(B-TPR)',\n",
    "               '(W-TNR)', '(B-TNR)',\n",
    "               '(W-FPR)', '(B-FPR)',\n",
    "               '(W-FNR)', '(B-FNR)',\n",
    "               'Accuracy (White)', 'Accuracy (Black)'],\n",
    "    'Value': [tx_equality_violation, tx_eq_odd_diff, tx_eq_odd_ratio,\n",
    "               true_parity, parity,\n",
    "               white_tpr, black_tpr, white_tnr, black_tnr, white_fpr, black_fpr, white_fnr, black_fnr,\n",
    "               white_accuracy, black_accuracy]\n",
    "}\n",
    "table_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(table_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group: 'RAC1P'for BW, prediction task ACSIncomePovertyRatio CA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, generate_categories\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
    "\n",
    "from scipy.stats import sem\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# import fairlearn\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import equalized_odds_ratio\n",
    "from fairlearn.metrics import true_positive_rate, false_positive_rate\n",
    "\n",
    "\n",
    "\n",
    "# The ACS data source contains data for all fifty states, each of which has a\n",
    "# slightly different distribution of features and response. This increases the\n",
    "# diversity of environments in which we can evaluate our methods. For instance, we\n",
    "# can generate another `ACSEmployment` task using data from Texas and repeat the\n",
    "# experiment\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "\n",
    "\n",
    "acs_tx = data_source.get_data(states=[\"TX\"], download=True)\n",
    "tx_features, tx_label, tx_group = ACSIncomePovertyRatio.df_to_numpy(acs_tx)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    tx_features, tx_label, tx_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "\n",
    "                              \n",
    "# print(len(y_test), len(yhat))\n",
    "# print(tx_features)\n",
    "# print(tx_label)\n",
    "# print(tx_group)\n",
    "\n",
    "\n",
    "    \n",
    "    #library imports\n",
    "tx_eq_odd_diff = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "tx_eq_odd_ratio = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "\n",
    "\n",
    "# print(\"Number of samples for the 'white' group:\", np.sum((y_test == 1) & (group_test == 1)))\n",
    "\n",
    "print(\"Number of samples for the 'white' group:\", np.sum((group_test == 1)))\n",
    "\n",
    "# print(\"Number of samples for the 'black' group:\", np.sum((y_test == 1) & (group_test == 2)))\n",
    "\n",
    "print(\"Number of samples for the 'black' group:\", np.sum((group_test == 2)))\n",
    "\n",
    "# white_fpr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "white_fpr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "black_fpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "white_tnr = 1 - white_fpr\n",
    "# white_tnr = np.mean(yhat[(y_test == 0) & (group_test == 0)])\n",
    "# white_tnr = 1- white_fpr\n",
    "black_tnr = np.mean(yhat[(y_test == 0) & (group_test == 1)])\n",
    "\n",
    "\n",
    "\n",
    "# fnr = 1- tpr ? (getting nan otherwise)\n",
    "\n",
    "# TODO: Figure out why empty slice for W partition but not B / and M not F??)\n",
    "# white_fnr = np.mean(yhat[(y_test == 1) & (group_test == 0)])\n",
    "white_fnr = 1 - white_tpr  \n",
    "black_fnr = np.mean(yhat[(y_test == 0) & (group_test == 2)])\n",
    "\n",
    "white_accuracy = accuracy_score(y_test[group_test == 1], yhat[group_test == 1])\n",
    "black_accuracy = accuracy_score(y_test[group_test == 2], yhat[group_test == 2])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Equality of opportunity violation: 0.0397\n",
    "tx_equality_violation = white_tpr - black_tpr\n",
    "\n",
    "\n",
    "\n",
    "true_parity = np.abs(true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) - true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)]))\n",
    "parity = (true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) + true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)])) / 2\n",
    "\n",
    "\n",
    "print(\"Texas Data\")\n",
    "print(\"Predicting Income By Race (B/W)\")\n",
    "data = {\n",
    "    'Metric': ['Equality Violation', 'Eq Odds Difference', 'Eq Odds Ratio',\n",
    "               'True Parity', 'Parity',\n",
    "               '(W-TPR)', '(B-TPR)',\n",
    "               '(W-TNR)', '(B-TNR)',\n",
    "               '(W-FPR)', '(B-FPR)',\n",
    "               '(W-FNR)', '(B-FNR)',\n",
    "               'Accuracy (White)', 'Accuracy (Black)'],\n",
    "    'Value': [tx_equality_violation, tx_eq_odd_diff, tx_eq_odd_ratio,\n",
    "               true_parity, parity,\n",
    "               white_tpr, black_tpr, white_tnr, black_tnr, white_fpr, black_fpr, white_fnr, black_fnr,\n",
    "               white_accuracy, black_accuracy]\n",
    "}\n",
    "table_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(table_df)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
