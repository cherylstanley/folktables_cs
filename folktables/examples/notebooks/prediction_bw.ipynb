{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equality of Opportunity : TPR of group 1 = TPR of group 2\n",
    "\n",
    "Equality violation = TPR group 1 - TPR Group 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ACSIncome_categories object (df_topandas expects a categories object) -- not used here though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ACSIncome_categories = {\n",
    "    \"COW\": {\n",
    "        1.0: (\n",
    "            \"Employee of a private for-profit company or\"\n",
    "            \"business, or of an individual, for wages,\"\n",
    "            \"salary, or commissions\"\n",
    "        ),\n",
    "        2.0: (\n",
    "            \"Employee of a private not-for-profit, tax-exempt,\"\n",
    "            \"or charitable organization\"\n",
    "        ),\n",
    "        3.0: \"Local government employee (city, county, etc.)\",\n",
    "        4.0: \"State government employee\",\n",
    "        5.0: \"Federal government employee\",\n",
    "        6.0: (\n",
    "            \"Self-employed in own not incorporated business,\"\n",
    "            \"professional practice, or farm\"\n",
    "        ),\n",
    "        7.0: (\n",
    "            \"Self-employed in own incorporated business,\"\n",
    "            \"professional practice or farm\"\n",
    "        ),\n",
    "        8.0: \"Working without pay in family business or farm\",\n",
    "        9.0: \"Unemployed and last worked 5 years ago or earlier or never worked\",\n",
    "    },\n",
    "    \"SCHL\": {\n",
    "        1.0: \"No schooling completed\",\n",
    "        2.0: \"Nursery school, preschool\",\n",
    "        3.0: \"Kindergarten\",\n",
    "        4.0: \"Grade 1\",\n",
    "        5.0: \"Grade 2\",\n",
    "        6.0: \"Grade 3\",\n",
    "        7.0: \"Grade 4\",\n",
    "        8.0: \"Grade 5\",\n",
    "        9.0: \"Grade 6\",\n",
    "        10.0: \"Grade 7\",\n",
    "        11.0: \"Grade 8\",\n",
    "        12.0: \"Grade 9\",\n",
    "        13.0: \"Grade 10\",\n",
    "        14.0: \"Grade 11\",\n",
    "        15.0: \"12th grade - no diploma\",\n",
    "        16.0: \"Regular high school diploma\",\n",
    "        17.0: \"GED or alternative credential\",\n",
    "        18.0: \"Some college, but less than 1 year\",\n",
    "        19.0: \"1 or more years of college credit, no degree\",\n",
    "        20.0: \"Associate's degree\",\n",
    "        21.0: \"Bachelor's degree\",\n",
    "        22.0: \"Master's degree\",\n",
    "        23.0: \"Professional degree beyond a bachelor's degree\",\n",
    "        24.0: \"Doctorate degree\",\n",
    "    },\n",
    "    \"MAR\": {\n",
    "        1.0: \"Married\",\n",
    "        2.0: \"Widowed\",\n",
    "        3.0: \"Divorced\",\n",
    "        4.0: \"Separated\",\n",
    "        5.0: \"Never married or under 15 years old\",\n",
    "    },\n",
    "    \"SEX\": {1.0: \"Male\", 2.0: \"Female\"},\n",
    "    \"RAC1P\": {\n",
    "        1.0: \"White alone\",\n",
    "        2.0: \"Black or African American alone\",\n",
    "        3.0: \"American Indian alone\",\n",
    "        4.0: \"Alaska Native alone\",\n",
    "        5.0: (\n",
    "            \"American Indian and Alaska Native tribes specified;\"\n",
    "            \"or American Indian or Alaska Native,\"\n",
    "            \"not specified and no other\"\n",
    "        ),\n",
    "        6.0: \"Asian alone\",\n",
    "        7.0: \"Native Hawaiian and Other Pacific Islander alone\",\n",
    "        8.0: \"Some Other Race alone\",\n",
    "        9.0: \"Two or More Races\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is custom task ACSIncome based on the Folktables paper, and is used in cell \n",
    "# [C]\n",
    "group: RAC1P (Race)\n",
    "target: POVPIP (Income Poverty Ratio Recode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# \"\"\"Data source and problem definitions for American Community Survey (ACS) Public Use Microdata Sample (PUMS).\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import folktables\n",
    "\n",
    "ACSIncomePovertyRatio = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'SEX',\n",
    "        'DIS',\n",
    "        'ESP',\n",
    "        'MIG',\n",
    "        'CIT',\n",
    "        'MIL',\n",
    "        'ANC',\n",
    "        'NATIVITY',\n",
    "        'RELP',\n",
    "        'DEAR',\n",
    "        'DEYE',\n",
    "        'DREM',\n",
    "        'RAC1P',\n",
    "        'GCL',\n",
    "        'ESR',\n",
    "        'OCCP',\n",
    "        'WKHP',\n",
    "    ],\n",
    "    target='POVPIP',\n",
    "    target_transform=lambda x: x < 250,\n",
    "    group='RAC1P',\n",
    "    preprocess=lambda x: x,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is custom task ACSIncome based on the Folktables paper, and is used in cell \n",
    "# [A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ACSIncome = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'OCCP',\n",
    "        'POBP',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 50000,    \n",
    "    group='RAC1P',\n",
    "    preprocess=folktables.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is custom task ACSIncomeNew, and is used in cell :\n",
    "# [B]\n",
    "\n",
    "It has all the same features as ACSIncome from the paper but it does not use AGEP (Age), the group is 'SEX' instead of 'RAC1P', and it predicts income > 25000, not 50000 like ACSIncome did.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import folktables\n",
    "ACSIncomeNew = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'OCCP',\n",
    "        'POBP',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 25000,    \n",
    "    group='SEX',\n",
    "    preprocess=folktables.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [B]\n",
    "**Group: 'SEX'for MF, prediction task ACSIncomeNew CA**\n",
    "**CA -  ACSIncomeNew (income threshold  - $25,000 )**\n",
    "9 features\n",
    "target: PINCP\n",
    "group: SEX for MF\n",
    "\n",
    "individual's label is 1 if PINCP > 25000, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## California Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Predicting Income By Sex (M/F)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for the 'male' group: 20621\n",
      "Number of samples for the 'female' group: 18512\n",
      "\n",
      "\n",
      "\n",
      "╒════════════════════╤═══════════╕\n",
      "│ Metric             │     Value │\n",
      "╞════════════════════╪═══════════╡\n",
      "│ Equality Violation │ 0.0469655 │\n",
      "├────────────────────┼───────────┤\n",
      "│ Eq Odds Difference │ 0.11779   │\n",
      "├────────────────────┼───────────┤\n",
      "│ Eq Odds Ratio      │ 0.752538  │\n",
      "├────────────────────┼───────────┤\n",
      "│ True Parity        │ 0.0469655 │\n",
      "├────────────────────┼───────────┤\n",
      "│ Parity             │ 0.892167  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (M-TPR)            │ 0.91565   │\n",
      "├────────────────────┼───────────┤\n",
      "│ (F-TPR)            │ 0.868684  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (M-TNR)            │ 0.524007  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (F-TNR)            │ 0.641797  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (M-FPR)            │ 0.475993  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (F-FPR)            │ 0.358203  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (M-FNR)            │ 0.0843503 │\n",
      "├────────────────────┼───────────┤\n",
      "│ (F-FNR)            │ 0.131316  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Accuracy (Male)    │ 0.805684  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Accuracy (Female)  │ 0.780305  │\n",
      "╘════════════════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, generate_categories\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
    "\n",
    "from scipy.stats import sem\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# import fairlearn\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import equalized_odds_ratio\n",
    "from fairlearn.metrics import true_positive_rate, false_positive_rate\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "# The ACS data source contains data for all fifty states, each of which has a\n",
    "# slightly different distribution of features and response. This increases the\n",
    "# diversity of environments in which we can evaluate our methods. For instance, we\n",
    "# can generate another `ACSEmployment` task using data from Texas and repeat the\n",
    "# experiment\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_ca = data_source.get_data(states=[\"CA\"], download=True)\n",
    "\n",
    "ca_features, ca_label, ca_group = ACSIncomeNew.df_to_numpy(acs_ca)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    ca_features, ca_label, ca_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "#     library imports\n",
    "ca_eq_odd_diff = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "ca_eq_odd_ratio = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "\n",
    "\n",
    "male_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "female_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "male_tnr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 0)\n",
    "female_tnr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 0)\n",
    "\n",
    "\n",
    "\n",
    "male_fpr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 1)\n",
    "female_fpr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 1)\n",
    "\n",
    "\n",
    "\n",
    "male_fnr = np.mean(yhat[(y_test == 1) & (group_test == 1)] == 0)\n",
    "female_fnr = np.mean(yhat[(y_test == 1) & (group_test == 2)] == 0)\n",
    "\n",
    "male_accuracy = accuracy_score(y_test[group_test == 1], yhat[group_test == 1])\n",
    "female_accuracy = accuracy_score(y_test[group_test == 2], yhat[group_test == 2])\n",
    "\n",
    "# Equality of opportunity violation: \n",
    "ca_equality_violation = male_tpr - female_tpr\n",
    "\n",
    "\n",
    "\n",
    "true_parity = np.abs(true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) - true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)]))\n",
    "parity = (true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) + true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)])) / 2\n",
    "\n",
    "printmd(\"## California Data\")\n",
    "\n",
    "printmd(\"**Predicting Income By Sex (M/F)**\")\n",
    "\n",
    "print(\"Number of samples for the 'male' group:\", np.sum((group_test == 1)))\n",
    "\n",
    "\n",
    "print(\"Number of samples for the 'female' group:\", np.sum((group_test == 2)))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "data = {\n",
    "    'Metric': ['Equality Violation', 'Eq Odds Difference', 'Eq Odds Ratio',\n",
    "               'True Parity', 'Parity',\n",
    "               '(M-TPR)', '(F-TPR)',\n",
    "               '(M-TNR)', '(F-TNR)',\n",
    "               '(M-FPR)', '(F-FPR)',\n",
    "               '(M-FNR)', '(F-FNR)',\n",
    "               'Accuracy (Male)', 'Accuracy (Female)'],\n",
    "    'Value': [ca_equality_violation, ca_eq_odd_diff, ca_eq_odd_ratio,\n",
    "               true_parity, parity,\n",
    "               male_tpr, female_tpr, male_tnr, female_tnr, male_fpr, female_fpr, male_fnr, female_fnr,\n",
    "               male_accuracy, female_accuracy]\n",
    "}\n",
    "table_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(tabulate(table_df, showindex=False, headers=['Metric','Value'], tablefmt = \"fancy_grid\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Fairness Metrics:\n",
    "==================================================\n",
    "\n",
    "The above results show an **equality of opportunity violation** of approximately *0.047*.\n",
    "\n",
    "This showing that the rate of TPR is slightly higher than the Black group. In other words, the Male group has a higher likelihood of getting a positive prediction given a ground truth positive label, compared with the Female group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds difference** of approximately *0.118*, showing the error rates are slightly higher for the Male group compared to the Female group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds ratio** of *0.75* which is interesting because this implies the error rates for positives and negatives are leaning more one way or another\n",
    "\n",
    "The above results show an **true parity** of approximately *0.047*. It's slightly above 0 showing the error rates for classifying positive instances are slightly higher for the White group compared to the Female group. \n",
    "\n",
    "The above results show an **parity** of approximately *0.892*. It's closer to 1 than 0 showing the general error rates are significantly higher for the Male group compared to the Female group. \n",
    "\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "The above results show a *Male TPR* and *Female TPR* of approximately 91.5% and 86.9% respectively\n",
    "\n",
    "The above results show a *Male TNR* and *Female TNR* of approximately 52.4% and 64.1% respectively\n",
    "\n",
    "The above results show a *Male FPR* and *Female FPR* of approximately 47.5% and 35.8% respectively\n",
    "\n",
    "The above results show a *Male FNR* and *Female FNR* of approximately 8.4% and 13.1% respectively\n",
    "\n",
    "The above results show a *Male Accuracy* and *Female Accuracy* of approximately 80.5% and 75.2% respectively\n",
    "\n",
    "\n",
    "The above results show a lot of similarities with the eduML findings. \n",
    "\n",
    "**TPR:*\n",
    "\n",
    "For instance, like the eduML dataset, the results show that the Male TPR is higher than the Female TPR, with an almost 6% difference between the two. This indicates that there may be an inherent bias in the model's performance when classifiying positive instances in the Male ve Female group.\n",
    "\n",
    "**TNR:**\n",
    "The White TNR is actually significantly lower (~12%) than the Black TNR however, and there is higher disparity compared with the TPR, though both are large gaps. It does indicate some level of difference between model's performance with Male and Female groups in the dataset.\n",
    "\n",
    "\n",
    "**FPR**\n",
    "One interesting finding which echoes the eduML findings is the FPR gap. The Male FPR is slightly higher (1.3%) showing that White predictions for Income are more likely to get benefit of doubt for income level higher in the same way that White s\n",
    "\n",
    "**FNR**\n",
    "\n",
    "Another similarity with the eduML findings is the FNR gap. The Female FNR is significantly higher (5%) showing that Female groups higher than the income threshold are more likely to get a false prediction of being lower than the income threshold. \n",
    "\n",
    "This echoes the results from the eduML dataset and shows that some level of pre-processing still needs to be done to make the model more fair.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [B]\n",
    "**Group: 'SEX'for MF, prediction task ACSIncomeNew TX**\n",
    "**TX -  ACSIncomeNew (income threshold  - $25,000 )**\n",
    "9 features\n",
    "target: PINCP\n",
    "group: SEX for MF\n",
    "\n",
    "individual's label is 1 if PINCP > 25000, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Texas Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Predicting Income By Sex (M/F)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for the 'male' group: 14495\n",
      "Number of samples for the 'female' group: 12690\n",
      "\n",
      "\n",
      "\n",
      "╒════════════════════╤═══════════╕\n",
      "│ Metric             │     Value │\n",
      "╞════════════════════╪═══════════╡\n",
      "│ Equality Violation │ 0.0736927 │\n",
      "├────────────────────┼───────────┤\n",
      "│ Eq Odds Difference │ 0.125046  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Eq Odds Ratio      │ 0.734393  │\n",
      "├────────────────────┼───────────┤\n",
      "│ True Parity        │ 0.0736927 │\n",
      "├────────────────────┼───────────┤\n",
      "│ Parity             │ 0.879038  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (M-TPR)            │ 0.915884  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (F-TPR)            │ 0.842192  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (M-TNR)            │ 0.529209  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (F-TNR)            │ 0.654254  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (M-FPR)            │ 0.470791  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (F-FPR)            │ 0.345746  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (M-FNR)            │ 0.0841157 │\n",
      "├────────────────────┼───────────┤\n",
      "│ (F-FNR)            │ 0.157808  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Accuracy (Male)    │ 0.807658  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Accuracy (Female)  │ 0.762648  │\n",
      "╘════════════════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, generate_categories\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
    "\n",
    "from scipy.stats import sem\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# import fairlearn\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import equalized_odds_ratio\n",
    "from fairlearn.metrics import true_positive_rate, false_positive_rate\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "# The ACS data source contains data for all fifty states, each of which has a\n",
    "# slightly different distribution of features and response. This increases the\n",
    "# diversity of environments in which we can evaluate our methods. For instance, we\n",
    "# can generate another `ACSEmployment` task using data from Texas and repeat the\n",
    "# experiment\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_tx = data_source.get_data(states=[\"TX\"], download=True)\n",
    "\n",
    "tx_features, tx_label, tx_group = ACSIncomeNew.df_to_numpy(acs_tx)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    tx_features, tx_label, tx_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "#     library imports\n",
    "tx_eq_odd_diff = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "tx_eq_odd_ratio = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "\n",
    "\n",
    "male_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "female_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "male_tnr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 0)\n",
    "female_tnr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 0)\n",
    "\n",
    "\n",
    "\n",
    "male_fpr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 1)\n",
    "female_fpr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 1)\n",
    "\n",
    "\n",
    "\n",
    "male_fnr = np.mean(yhat[(y_test == 1) & (group_test == 1)] == 0)\n",
    "female_fnr = np.mean(yhat[(y_test == 1) & (group_test == 2)] == 0)\n",
    "\n",
    "male_accuracy = accuracy_score(y_test[group_test == 1], yhat[group_test == 1])\n",
    "female_accuracy = accuracy_score(y_test[group_test == 2], yhat[group_test == 2])\n",
    "\n",
    "# Equality of opportunity violation: \n",
    "tx_equality_violation = male_tpr - female_tpr\n",
    "\n",
    "\n",
    "\n",
    "true_parity = np.abs(true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) - true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)]))\n",
    "parity = (true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) + true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)])) / 2\n",
    "\n",
    "printmd(\"## Texas Data\")\n",
    "\n",
    "printmd(\"**Predicting Income By Sex (M/F)**\")\n",
    "\n",
    "print(\"Number of samples for the 'male' group:\", np.sum((group_test == 1)))\n",
    "\n",
    "\n",
    "print(\"Number of samples for the 'female' group:\", np.sum((group_test == 2)))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "data = {\n",
    "    'Metric': ['Equality Violation', 'Eq Odds Difference', 'Eq Odds Ratio',\n",
    "               'True Parity', 'Parity',\n",
    "               '(M-TPR)', '(F-TPR)',\n",
    "               '(M-TNR)', '(F-TNR)',\n",
    "               '(M-FPR)', '(F-FPR)',\n",
    "               '(M-FNR)', '(F-FNR)',\n",
    "               'Accuracy (Male)', 'Accuracy (Female)'],\n",
    "    'Value': [tx_equality_violation, tx_eq_odd_diff, tx_eq_odd_ratio,\n",
    "               true_parity, parity,\n",
    "               male_tpr, female_tpr, male_tnr, female_tnr, male_fpr, female_fpr, male_fnr, female_fnr,\n",
    "               male_accuracy, female_accuracy]\n",
    "}\n",
    "table_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(tabulate(table_df, showindex=False, headers=['Metric','Value'], tablefmt = \"fancy_grid\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Fairness Metrics:\n",
    "==================================================\n",
    "\n",
    "The above results show an **equality of opportunity violation** of approximately *0.073*.\n",
    "\n",
    "This showing that the rate of TPR is slightly higher than the Black group. In other words, the Male group has a higher likelihood of getting a positive prediction given a ground truth positive label, compared with the Female group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds difference** of approximately *0.125*, showing the error rates are higher for the Male group compared to the Female group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds ratio** of *0.73* which extremely high implying that there is an increased error rate either on the positive or negative side\n",
    "\n",
    "The above results show an **true parity** of approximately *0.074*. It's slightly above 0 showing the error rates for classifying positive instances are slightly higher for the Male group compared to the Female group. \n",
    "\n",
    "The above results show an **parity** of approximately *0.88*. It's closer to 1 than 0 showing the general error rates are significantly higher for the Male group compared to the Female group. \n",
    "\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "The above results show a *Male TPR* and *Female TPR* of approximately 91.5% and 84.2% respectively\n",
    "\n",
    "The above results show a *Male TNR* and *Female TNR* of approximately 47.1% and 34.6% respectively\n",
    "\n",
    "The above results show a *Male FPR* and *Female FPR* of approximately 47.1% and 34.6% respectively\n",
    "\n",
    "The above results show a *Male FNR* and *Female FNR* of approximately 25.0% and 34.5% respectively\n",
    "\n",
    "The above results show a *Male Accuracy* and *Female Accuracy* of approximately 78.6% and 75.2% respectively\n",
    "\n",
    "\n",
    "The above results show a lot of similarities with the eduML findings. \n",
    "\n",
    "**TPR:*\n",
    "\n",
    "For instance, like the eduML dataset, the results show that the White TPR is higher than the Black TPR, with an almost 10% difference between the two. This indicates that there may be an inherent bias in the model's performance when classifiying positive instances in the White ve Black group.\n",
    "\n",
    "**TNR:**\n",
    "The White TNR is actually lower (~1%) than the Black TNR however, but there is lesser disparity compared with the TPR. It does indicate some level of difference between model's performance with Black and White groups in the dataset.\n",
    "\n",
    "\n",
    "**FPR**\n",
    "One interesting finding which echoes the eduML findings is the FPR gap. The White FPR is slightly higher (1.3%) showing that White predictions for Income are more likely to get benefit of doubt for income level higher in the same way that White s\n",
    "\n",
    "**FNR**\n",
    "\n",
    "Another similarity with the eduML findings is the FNR gap. The Black FNR is significantly higher (11.4%) showing that Black groups higher than the income threshold are more likely to get a false prediction of being lower than the income threshold. \n",
    "\n",
    "This echoes the results from the eduML dataset and shows that some level of pre-processing still needs to be done to make the model more fair.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# [A]\n",
    "\n",
    "**CA -  ACSIncome (income threshold  - $50,000 )**\n",
    "10 features\n",
    "target: PINCP\n",
    "group: RAC1P for BW\n",
    "\n",
    "individual's label is 1 if PINCP > 50000, 0 otherwise\n",
    "\n",
    "(imports and data download are in previous cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## California Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Predicting Income By Race (B/W)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for the 'white' group: 24197\n",
      "Number of samples for the 'black' group: 1698\n",
      "\n",
      "\n",
      "\n",
      "╒════════════════════╤═══════════╕\n",
      "│ Metric             │     Value │\n",
      "╞════════════════════╪═══════════╡\n",
      "│ Equality Violation │ 0.0944656 │\n",
      "├────────────────────┼───────────┤\n",
      "│ Eq Odds Difference │ 0.362903  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Eq Odds Ratio      │ 0         │\n",
      "├────────────────────┼───────────┤\n",
      "│ True Parity        │ 0.0944656 │\n",
      "├────────────────────┼───────────┤\n",
      "│ Parity             │ 0.702627  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-TPR)            │ 0.74986   │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-TPR)            │ 0.655395  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-TNR)            │ 0.814397  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-TNR)            │ 0.807799  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-FPR)            │ 0.185603  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-FPR)            │ 0.192201  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-FNR)            │ 0.25014   │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-FNR)            │ 0.344605  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Accuracy (White)   │ 0.7858    │\n",
      "├────────────────────┼───────────┤\n",
      "│ Accuracy (Black)   │ 0.752061  │\n",
      "╘════════════════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "# ca label, ca_features, ca_group, be able to explain what that value is and what values from 1-8 for example in CA_group\n",
    "# do histogram to understand each specific understanding of what they are\n",
    "# really good understanding of data for data analysis\n",
    "# which features are useful for group label, predictions\n",
    "# nan value because denominator is 0 and group label might not be 1 and 2\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "    \n",
    "ca_features, ca_label, ca_group = ACSIncome.df_to_numpy(acs_ca)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    ca_features, ca_label, ca_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "\n",
    "    \n",
    "#     library imports\n",
    "ca_eq_odd_diff = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "ca_eq_odd_ratio = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "white_tnr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 0)\n",
    "black_tnr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 0)\n",
    "\n",
    "\n",
    "\n",
    "white_fpr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 1)\n",
    "black_fpr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 1)\n",
    "\n",
    "\n",
    "\n",
    "white_fnr = np.mean(yhat[(y_test == 1) & (group_test == 1)] == 0)\n",
    "black_fnr = np.mean(yhat[(y_test == 1) & (group_test == 2)] == 0)\n",
    "\n",
    "white_accuracy = accuracy_score(y_test[group_test == 1], yhat[group_test == 1])\n",
    "black_accuracy = accuracy_score(y_test[group_test == 2], yhat[group_test == 2])\n",
    "\n",
    "# Equality of opportunity violation: \n",
    "ca_equality_violation = white_tpr - black_tpr\n",
    "\n",
    "\n",
    "\n",
    "true_parity = np.abs(true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) - true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)]))\n",
    "parity = (true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) + true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)])) / 2\n",
    "\n",
    "printmd(\"## California Data\")\n",
    "\n",
    "printmd(\"**Predicting Income By Race (B/W)**\")\n",
    "\n",
    "print(\"Number of samples for the 'white' group:\", np.sum((group_test == 1)))\n",
    "\n",
    "\n",
    "print(\"Number of samples for the 'black' group:\", np.sum((group_test == 2)))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "data = {\n",
    "    'Metric': ['Equality Violation', 'Eq Odds Difference', 'Eq Odds Ratio',\n",
    "               'True Parity', 'Parity',\n",
    "               '(W-TPR)', '(B-TPR)',\n",
    "               '(W-TNR)', '(B-TNR)',\n",
    "               '(W-FPR)', '(B-FPR)',\n",
    "               '(W-FNR)', '(B-FNR)',\n",
    "               'Accuracy (White)', 'Accuracy (Black)'],\n",
    "    'Value': [ca_equality_violation, ca_eq_odd_diff, ca_eq_odd_ratio,\n",
    "               true_parity, parity,\n",
    "               white_tpr, black_tpr, white_tnr, black_tnr, white_fpr, black_fpr, white_fnr, black_fnr,\n",
    "               white_accuracy, black_accuracy]\n",
    "}\n",
    "table_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(tabulate(table_df, showindex=False, headers=['Metric','Value'], tablefmt = \"fancy_grid\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Fairness Metrics:\n",
    "==================================================\n",
    "\n",
    "The above results show an **equality of opportunity violation** of approximately *0.094*.\n",
    "\n",
    "This showing that the rate of TPR is slightly higher than the Black group. In other words, the White group has a higher likelihood of getting a positive prediction given a ground truth positive label, compared with the Black group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds difference** of approximately *0.362*, showing the error rates are slightly higher for the White group compared to the Black group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds ratio** of *0* which is interesting because this implies the error rates for positives and negatives are pretty much the same.\n",
    "\n",
    "The above results show an **true parity** of approximately *0.094*. It's slightly above 0 showing the error rates for classifying positive instances are slightly higher for the White group compared to the Black group. \n",
    "\n",
    "The above results show an **parity** of approximately *0.702*. It's closer to 1 than 0 showing the general error rates are significantly higher for the White group compared to the Black group. \n",
    "\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "The above results show a *White TPR* and *Black TPR* of approximately 74.9% and 65.5% respectively\n",
    "\n",
    "The above results show a *White TNR* and *Black TNR* of approximately 18.6% and 19.2% respectively\n",
    "\n",
    "The above results show a *White FPR* and *Black FPR* of approximately 18.6% and 19.2% respectively\n",
    "\n",
    "The above results show a *White FNR* and *Black FNR* of approximately 25.0% and 34.5% respectively\n",
    "\n",
    "The above results show a *White Accuracy* and *Black Accuracy* of approximately 78.6% and 75.2% respectively\n",
    "\n",
    "\n",
    "The above results show a lot of similarities with the eduML findings. \n",
    "\n",
    "**TPR:*\n",
    "\n",
    "For instance, like the eduML dataset, the results show that the White TPR is higher than the Black TPR, with an almost 10% difference between the two. This indicates that there may be an inherent bias in the model's performance when classifiying positive instances in the White ve Black group.\n",
    "\n",
    "**TNR:**\n",
    "The White TNR is actually lower (~1%) than the Black TNR however, but there is lesser disparity compared with the TPR. It does indicate some level of difference between model's performance with Black and White groups in the dataset.\n",
    "\n",
    "\n",
    "**FPR**\n",
    "One interesting finding which echoes the eduML findings is the FPR gap. The White FPR is slightly higher (1.3%) showing that White predictions for Income are more likely to get benefit of doubt for income level higher in the same way that White s\n",
    "\n",
    "**FNR**\n",
    "\n",
    "Another similarity with the eduML findings is the FNR gap. The Black FNR is significantly higher (11.4%) showing that Black groups higher than the income threshold are more likely to get a false prediction of being lower than the income threshold. \n",
    "\n",
    "This echoes the results from the eduML dataset and shows that some level of pre-processing still needs to be done to make the model more fair.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [A]\n",
    "\n",
    "**TX -  ACSIncome (income threshold  - $50,000 )**\n",
    "10 features\n",
    "target: PINCP\n",
    "Group: RAC1P for BW\n",
    "individual's label is 1 if PINCP > 50000, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Texas Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Predicting Income By Race (B/W)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for the 'white' group: 21184\n",
      "Number of samples for the 'black' group: 2467\n",
      "\n",
      "\n",
      "\n",
      "╒════════════════════╤══════════╕\n",
      "│ Metric             │    Value │\n",
      "╞════════════════════╪══════════╡\n",
      "│ Equality Violation │ 0.132597 │\n",
      "├────────────────────┼──────────┤\n",
      "│ Eq Odds Difference │ 0.39469  │\n",
      "├────────────────────┼──────────┤\n",
      "│ Eq Odds Ratio      │ 0.241306 │\n",
      "├────────────────────┼──────────┤\n",
      "│ True Parity        │ 0.132597 │\n",
      "├────────────────────┼──────────┤\n",
      "│ Parity             │ 0.598056 │\n",
      "├────────────────────┼──────────┤\n",
      "│ (W-TPR)            │ 0.664355 │\n",
      "├────────────────────┼──────────┤\n",
      "│ (B-TPR)            │ 0.531758 │\n",
      "├────────────────────┼──────────┤\n",
      "│ (W-TNR)            │ 0.851126 │\n",
      "├────────────────────┼──────────┤\n",
      "│ (B-TNR)            │ 0.869832 │\n",
      "├────────────────────┼──────────┤\n",
      "│ (W-FPR)            │ 0.148874 │\n",
      "├────────────────────┼──────────┤\n",
      "│ (B-FPR)            │ 0.130168 │\n",
      "├────────────────────┼──────────┤\n",
      "│ (W-FNR)            │ 0.335645 │\n",
      "├────────────────────┼──────────┤\n",
      "│ (B-FNR)            │ 0.468242 │\n",
      "├────────────────────┼──────────┤\n",
      "│ Accuracy (White)   │ 0.778654 │\n",
      "├────────────────────┼──────────┤\n",
      "│ Accuracy (Black)   │ 0.777057 │\n",
      "╘════════════════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, generate_categories\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
    "\n",
    "from scipy.stats import sem\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# import fairlearn\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import equalized_odds_ratio\n",
    "from fairlearn.metrics import true_positive_rate, false_positive_rate\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "# The ACS data source contains data for all fifty states, each of which has a\n",
    "# slightly different distribution of features and response. This increases the\n",
    "# diversity of environments in which we can evaluate our methods. For instance, we\n",
    "# can generate another `ACSEmployment` task using data from Texas and repeat the\n",
    "# experiment\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "\n",
    "\n",
    "acs_tx = data_source.get_data(states=[\"TX\"], download=True)\n",
    "tx_features, tx_label, tx_group = ACSIncome.df_to_numpy(acs_tx)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    tx_features, tx_label, tx_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "\n",
    "                            \n",
    "# library imports\n",
    "tx_eq_odd_diff = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "tx_eq_odd_ratio = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "white_tnr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 0)\n",
    "black_tnr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 0)\n",
    "\n",
    "white_fpr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 1)\n",
    "black_fpr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 1)\n",
    "\n",
    "white_fnr = np.mean(yhat[(y_test == 1) & (group_test == 1)] == 0)\n",
    "black_fnr = np.mean(yhat[(y_test == 1) & (group_test == 2)] == 0)\n",
    "\n",
    "white_accuracy = accuracy_score(y_test[group_test == 1], yhat[group_test == 1])\n",
    "black_accuracy = accuracy_score(y_test[group_test == 2], yhat[group_test == 2])\n",
    "\n",
    "\n",
    "# Equality of opportunity violation:\n",
    "tx_equality_violation = white_tpr - black_tpr\n",
    "\n",
    "\n",
    "\n",
    "true_parity = np.abs(true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) - true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)]))\n",
    "parity = (true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) + true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)])) / 2\n",
    "\n",
    "\n",
    "printmd(\"## Texas Data\")\n",
    "\n",
    "printmd(\"**Predicting Income By Race (B/W)**\")\n",
    "\n",
    "print(\"Number of samples for the 'white' group:\", np.sum((group_test == 1)))\n",
    "\n",
    "\n",
    "print(\"Number of samples for the 'black' group:\", np.sum((group_test == 2)))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "data = {\n",
    "    'Metric': ['Equality Violation', 'Eq Odds Difference', 'Eq Odds Ratio',\n",
    "               'True Parity', 'Parity',\n",
    "               '(W-TPR)', '(B-TPR)',\n",
    "               '(W-TNR)', '(B-TNR)',\n",
    "               '(W-FPR)', '(B-FPR)',\n",
    "               '(W-FNR)', '(B-FNR)',\n",
    "               'Accuracy (White)', 'Accuracy (Black)'],\n",
    "    'Value': [tx_equality_violation, tx_eq_odd_diff, tx_eq_odd_ratio,\n",
    "               true_parity, parity,\n",
    "               white_tpr, black_tpr, white_tnr, black_tnr, white_fpr, black_fpr, white_fnr, black_fnr,\n",
    "               white_accuracy, black_accuracy]\n",
    "}\n",
    "table_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(tabulate(table_df, showindex=False, headers=['Metric','Value'], tablefmt = \"fancy_grid\" ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Fairness Metrics:\n",
    "==================================================\n",
    "\n",
    "The above results show an **equality of opportunity violation** of approximately *0.132*.\n",
    "\n",
    "This showing that the rate of TPR / accurately predicted positives juxtaposed with ground truth positives from the training data for the White group is significantly higher than the Black group. In other words, the White group has a higher likelihood of getting a positive prediction given a ground truth positive label, compared with the Black group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds difference** of approximately *0.394*. It's slightly above 0 showing the error rates are slightly higher for the White group compared to the Black group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds ratio** of approximately *0.241*. It's slightly above 0 showing the error rates are slightly higher for the White group compared to the Black group. \n",
    "\n",
    "The above results show an **true parity** of approximately *0.132*. It's slightly above 0 showing the error rates for classifying positive instances are slightly higher for the White group compared to the Black group. \n",
    "\n",
    "The above results show an **parity** of approximately *0.598*. It's well above 0 and closer to 1 showing the general error rates are significantly higher for the White group compared to the Black group. \n",
    "\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "The above results show a *White TPR* and *Black TPR* of approximately 66.5% and 53.1% respectively\n",
    "\n",
    "The above results show a *White TNR* and *Black TNR* of approximately 85.1% and 86.9% respectively\n",
    "\n",
    "The above results show a *White FPR* and *Black FPR* of approximately 14.9% and 13.0% respectively\n",
    "\n",
    "The above results show a *White FNR* and *Black FNR* of approximately 33.6% and 46.8% respectively\n",
    "\n",
    "The above results show a *White Accuracy* and *Black Accuracy* of approximately 77.8% and 77.7% respectively\n",
    "\n",
    "\n",
    "The above results show a lot of similarities with the eduML findings. \n",
    "\n",
    "**TPR:*\n",
    "\n",
    "For instance, like the eduML dataset, the results show that the White TPR is higher than the Black TPR, with an almost 13% difference between the two. This indicates that there may be an inherent bias in the model's performance when classifiying positive instances in the White ve Black group.\n",
    "\n",
    "**TNR:**\n",
    "The White TNR is actually lower (~1.8%) than the Black TNR however, but there is lesser disparity compared with the TPR. It does indicate some level of difference between model's performance with Black and White groups in the dataset and that prediction of negatives is lower for the White group (possible bias).\n",
    "\n",
    "\n",
    "**FPR**\n",
    "One interesting finding which echoes the eduML findings is the FPR gap. The White FPR is slightly higher (1.8%) showing that White predictions for Income are more likely to get benefit of doubt for income level higher in the same way that White students were more likely to get benefit of the doubt for positive predictions for readiness for advanced math in the MSS/HSLS datasets.\n",
    "\n",
    "**FNR**\n",
    "\n",
    "Another similarity with the eduML findings is the FNR gap. The Black FNR is significantly higher (13.3%) showing that Black groups higher than the income threshold are more likely to get a false prediction of being lower than the income threshold. This parallels the eduML dataset and findings in that Black students were also more likely to be falsely predicted to do poorly in advanced math even when ground truth showed they would do well.\n",
    "\n",
    "This echoes the results from the eduML dataset and shows that some level of pre-processing still needs to be done to make the model more fair.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [C]\n",
    "\n",
    "**TX -  ACSIncomePovertyRatio (income threshold  - $250 )**\n",
    "10 features\n",
    "target: POVPIP\n",
    "Group: RAC1P for BW\n",
    "individual's label is 1 if PINCP > 250, 0 otherwise\n",
    "**Group: 'RAC1P'for BW, prediction task ACSIncomePovertyRatio TX**\n",
    "group: RAC1P (Race)\n",
    "target: POVPIP (Income Poverty Ratio Recode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Texas Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Predicting Income Poverty Ratio By Race (B/W)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for the 'white' group: 41739\n",
      "Number of samples for the 'black' group: 5072\n",
      "\n",
      "\n",
      "\n",
      "╒════════════════════╤═══════════╕\n",
      "│ Metric             │     Value │\n",
      "╞════════════════════╪═══════════╡\n",
      "│ Equality Violation │ 0.0731338 │\n",
      "├────────────────────┼───────────┤\n",
      "│ Eq Odds Difference │ 0.529032  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Eq Odds Ratio      │ 0         │\n",
      "├────────────────────┼───────────┤\n",
      "│ True Parity        │ 0.0731338 │\n",
      "├────────────────────┼───────────┤\n",
      "│ Parity             │ 0.429779  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-TPR)            │ 0.393212  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-TPR)            │ 0.466346  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-TNR)            │ 0.872892  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-TNR)            │ 0.832974  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-FPR)            │ 0.127108  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-FPR)            │ 0.167026  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-FNR)            │ 0.606788  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-FNR)            │ 0.533654  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Accuracy (White)   │ 0.701886  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Accuracy (Black)   │ 0.667587  │\n",
      "╘════════════════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, generate_categories\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.stats import sem\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# import fairlearn\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import equalized_odds_ratio\n",
    "from fairlearn.metrics import true_positive_rate, false_positive_rate\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "    \n",
    "\n",
    "# The ACS data source contains data for all fifty states, each of which has a\n",
    "# slightly different distribution of features and response. This increases the\n",
    "# diversity of environments in which we can evaluate our methods. For instance, we\n",
    "# can generate another `ACSEmployment` task using data from Texas and repeat the\n",
    "# experiment\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "\n",
    "\n",
    "acs_tx = data_source.get_data(states=[\"TX\"], download=True)\n",
    "tx_features, tx_label, tx_group = ACSIncomePovertyRatio.df_to_numpy(acs_tx)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    tx_features, tx_label, tx_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "\n",
    "    \n",
    "    #library imports\n",
    "tx_eq_odd_diff = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "tx_eq_odd_ratio = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "white_tnr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 0)\n",
    "black_tnr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 0)\n",
    "\n",
    "\n",
    "\n",
    "white_fpr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 1)\n",
    "black_fpr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 1)\n",
    "\n",
    "\n",
    "\n",
    "white_fnr = np.mean(yhat[(y_test == 1) & (group_test == 1)] == 0)\n",
    "black_fnr = np.mean(yhat[(y_test == 1) & (group_test == 2)] == 0)\n",
    "\n",
    "white_accuracy = accuracy_score(y_test[group_test == 1], yhat[group_test == 1])\n",
    "black_accuracy = accuracy_score(y_test[group_test == 2], yhat[group_test == 2])\n",
    "\n",
    "# Equality of opportunity violation: \n",
    "tx_equality_violation = np.abs(white_tpr - black_tpr)\n",
    "\n",
    "\n",
    "\n",
    "true_parity = np.abs(true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) - true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)]))\n",
    "parity = (true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) + true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)])) / 2\n",
    "\n",
    "printmd(\"## Texas Data\")\n",
    "\n",
    "printmd(\"**Predicting Income Poverty Ratio By Race (B/W)**\")\n",
    "\n",
    "print(\"Number of samples for the 'white' group:\", np.sum((group_test == 1)))\n",
    "\n",
    "# print(\"Number of samples for the 'black' group:\", np.sum((y_test == 1) & (group_test == 2)))\n",
    "\n",
    "print(\"Number of samples for the 'black' group:\", np.sum((group_test == 2)))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "data = {\n",
    "    'Metric': ['Equality Violation', 'Eq Odds Difference', 'Eq Odds Ratio',\n",
    "               'True Parity', 'Parity',\n",
    "               '(W-TPR)', '(B-TPR)',\n",
    "               '(W-TNR)', '(B-TNR)',\n",
    "               '(W-FPR)', '(B-FPR)',\n",
    "               '(W-FNR)', '(B-FNR)',\n",
    "               'Accuracy (White)', 'Accuracy (Black)'],\n",
    "    'Value': [tx_equality_violation, tx_eq_odd_diff, tx_eq_odd_ratio,\n",
    "               true_parity, parity,\n",
    "               white_tpr, black_tpr, white_tnr, black_tnr, white_fpr, black_fpr, white_fnr, black_fnr,\n",
    "               white_accuracy, black_accuracy]\n",
    "}\n",
    "table_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(tabulate(table_df, showindex=False, headers=['Metric','Value'], tablefmt = \"fancy_grid\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Fairness Metrics:\n",
    "==================================================\n",
    "\n",
    "The above results show an **equality of opportunity violation** of approximately *0.073*.\n",
    "\n",
    "This shows the TPR difference and that the White group has a slightly higher likelihood of getting a positive prediction given a ground truth positive label, compared with the Black group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds difference** of approximately *0.529*. It's halfway between 0 and 1 showing the error rates for positives and negatives are equalized for the White group and the Black group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds ratio** is exactly *0* which is interesting because this implies error rates are equalized in the positive and negative direction\n",
    "\n",
    "The above results show an **true parity** of approximately *0.073*. It's slightly above 0 showing the error rates for classifying positive instances are slightly higher for the White group compared to the Black group. \n",
    "\n",
    "The above results show an **parity** of approximately *0.429*. It's well above 0 and closer to 0.5 showing the general error rates are somewhat equalized for positives and negatives for the White group and for the Black group. \n",
    "\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "The above results show a *White TPR* and *Black TPR* of approximately 39.3% and 46.6% respectively\n",
    "\n",
    "The above results show a *White TNR* and *Black TNR* of approximately 87.3% and 83.3% respectively\n",
    "\n",
    "The above results show a *White FPR* and *Black FPR* of approximately 12.7% and 16.7% respectively\n",
    "\n",
    "The above results show a *White FNR* and *Black FNR* of approximately 60.7% and 53.4% respectively\n",
    "\n",
    "The above results show a *White Accuracy* and *Black Accuracy* of approximately 70.2% and 66.7% respectively\n",
    "\n",
    "\n",
    "The above results show a lot of similarities with the eduML findings. \n",
    "\n",
    "**TPR:*\n",
    "\n",
    "For instance, like the eduML dataset, the results show that the White TPR is higher than the Black TPR, with an almost 7% difference between the two. This indicates that there may be an inherent bias in the model's performance when classifiying positive instances in the White ve Black group.\n",
    "\n",
    "**TNR:**\n",
    "The White TNR is moderately higher (4%) than the Black TNR however, and there is comparable gaps disparity with the TPR. It does indicate some level of difference between model's performance with Black and White groups in the dataset.\n",
    "\n",
    "\n",
    "**FPR**\n",
    "One interesting finding which differs from the eduML findings is the FPR gap. The White FPR is actually a lot lower (4%) showing that White predictions for Income are actually less likely to get benefit of doubt for income level higher, whereas in the eduML dataset the opposite was true.\n",
    "\n",
    "**FNR**\n",
    "\n",
    "Another similarity with the eduML findings is the FNR gap. The Black FNR is actually higher (7.3%) showing that White groups higher than the income threshold are more likely to get a false prediction of being lower than the income threshold. \n",
    "\n",
    "This shows results which are opposite from the eduML dataset which is quite interesting as White group is penalized more but the White group seems to have a higher accuracy than the Black group.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [C]\n",
    "\n",
    "**CA -  ACSIncomePovertyRatio (income threshold  - $250 )**\n",
    "10 features\n",
    "target: POVPIP\n",
    "Group: RAC1P for BW\n",
    "individual's label is 1 if PINCP > 250, 0 otherwise\n",
    "**Group: 'RAC1P'for BW, prediction task ACSIncomePovertyRatio CA**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## California Data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Predicting Income Poverty Ratio By Race (B/W)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for the 'white' group: 46245\n",
      "Number of samples for the 'black' group: 3691\n",
      "\n",
      "\n",
      "\n",
      "╒════════════════════╤═══════════╕\n",
      "│ Metric             │     Value │\n",
      "╞════════════════════╪═══════════╡\n",
      "│ Equality Violation │ 0.0494294 │\n",
      "├────────────────────┼───────────┤\n",
      "│ Eq Odds Difference │ 0.456793  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Eq Odds Ratio      │ 0         │\n",
      "├────────────────────┼───────────┤\n",
      "│ True Parity        │ 0.0494294 │\n",
      "├────────────────────┼───────────┤\n",
      "│ Parity             │ 0.326405  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-TPR)            │ 0.301691  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-TPR)            │ 0.35112   │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-TNR)            │ 0.911361  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-TNR)            │ 0.88081   │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-FPR)            │ 0.0886388 │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-FPR)            │ 0.11919   │\n",
      "├────────────────────┼───────────┤\n",
      "│ (W-FNR)            │ 0.698309  │\n",
      "├────────────────────┼───────────┤\n",
      "│ (B-FNR)            │ 0.64888   │\n",
      "├────────────────────┼───────────┤\n",
      "│ Accuracy (White)   │ 0.718737  │\n",
      "├────────────────────┼───────────┤\n",
      "│ Accuracy (Black)   │ 0.662964  │\n",
      "╘════════════════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, generate_categories\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
    "\n",
    "from scipy.stats import sem\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# import fairlearn\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import equalized_odds_ratio\n",
    "from fairlearn.metrics import true_positive_rate, false_positive_rate\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "\n",
    "# The ACS data source contains data for all fifty states, each of which has a\n",
    "# slightly different distribution of features and response. This increases the\n",
    "# diversity of environments in which we can evaluate our methods. For instance, we\n",
    "# can generate another `ACSEmployment` task using data from Texas and repeat the\n",
    "# experiment\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "\n",
    "\n",
    "acs_ca = data_source.get_data(states=[\"CA\"], download=True)\n",
    "ca_features, ca_label, ca_group = ACSIncomePovertyRatio.df_to_numpy(acs_ca)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    ca_features, ca_label, ca_group, test_size=0.2, random_state=0)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "\n",
    "    \n",
    "#     library imports\n",
    "ca_eq_odd_diff = equalized_odds_difference(y_test, yhat, sensitive_features=group_test)\n",
    "ca_eq_odd_ratio = equalized_odds_ratio(y_test, yhat, sensitive_features=group_test)\n",
    "\n",
    "\n",
    "white_tpr = np.mean(yhat[(y_test == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(yhat[(y_test == 1) & (group_test == 2)])\n",
    "\n",
    "white_tnr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 0)\n",
    "black_tnr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 0)\n",
    "\n",
    "\n",
    "\n",
    "white_fpr = np.mean(yhat[(y_test == 0) & (group_test == 1)] == 1)\n",
    "black_fpr = np.mean(yhat[(y_test == 0) & (group_test == 2)] == 1)\n",
    "\n",
    "\n",
    "\n",
    "white_fnr = np.mean(yhat[(y_test == 1) & (group_test == 1)] == 0)\n",
    "black_fnr = np.mean(yhat[(y_test == 1) & (group_test == 2)] == 0)\n",
    "\n",
    "white_accuracy = accuracy_score(y_test[group_test == 1], yhat[group_test == 1])\n",
    "black_accuracy = accuracy_score(y_test[group_test == 2], yhat[group_test == 2])\n",
    "\n",
    "# Equality of opportunity violation: \n",
    "ca_equality_violation = np.abs(white_tpr - black_tpr)\n",
    "\n",
    "\n",
    "\n",
    "true_parity = np.abs(true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) - true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)]))\n",
    "parity = (true_positive_rate(y_test[(group_test == 1)], yhat[(group_test == 1)]) + true_positive_rate(y_test[(group_test == 2)], yhat[(group_test == 2)])) / 2\n",
    "\n",
    "printmd(\"## California Data\")\n",
    "\n",
    "printmd(\"**Predicting Income Poverty Ratio By Race (B/W)**\")\n",
    "\n",
    "print(\"Number of samples for the 'white' group:\", np.sum((group_test == 1)))\n",
    "\n",
    "# print(\"Number of samples for the 'black' group:\", np.sum((y_test == 1) & (group_test == 2)))\n",
    "\n",
    "print(\"Number of samples for the 'black' group:\", np.sum((group_test == 2)))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "data = {\n",
    "    'Metric': ['Equality Violation', 'Eq Odds Difference', 'Eq Odds Ratio',\n",
    "               'True Parity', 'Parity',\n",
    "               '(W-TPR)', '(B-TPR)',\n",
    "               '(W-TNR)', '(B-TNR)',\n",
    "               '(W-FPR)', '(B-FPR)',\n",
    "               '(W-FNR)', '(B-FNR)',\n",
    "               'Accuracy (White)', 'Accuracy (Black)'],\n",
    "    'Value': [ca_equality_violation, ca_eq_odd_diff, ca_eq_odd_ratio,\n",
    "               true_parity, parity,\n",
    "               white_tpr, black_tpr, white_tnr, black_tnr, white_fpr, black_fpr, white_fnr, black_fnr,\n",
    "               white_accuracy, black_accuracy]\n",
    "}\n",
    "table_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(tabulate(table_df, showindex=False, headers=['Metric','Value'], tablefmt = \"fancy_grid\" ))\n",
    "\n",
    "                              \n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Fairness Metrics:\n",
    "==================================================\n",
    "\n",
    "The above results show an **equality of opportunity violation** of approximately *0.049*.\n",
    "\n",
    "This shows the TPR difference and that the White group has a slightly higher likelihood of getting a positive prediction given a ground truth positive label, compared with the Black group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds difference** of approximately *0.457*. It's halfway between 0 and 1 showing the error rates for positives and negatives are equalized for the White group and the Black group\n",
    "\n",
    "\n",
    "The above results show an **equalized odds ratio** is exactly *0* which is interesting because this implies error rates are equalized in the positive and negative direction\n",
    "\n",
    "The above results show an **true parity** of approximately *0.049*. It's slightly above 0 showing the error rates for classifying positive instances are slightly higher for the White group compared to the Black group. \n",
    "\n",
    "The above results show an **parity** of approximately *0.326*. It's above 0 and closer to 0.4 showing the general error rates are somewhat equalized for positives and negatives for the White group and for the Black group. \n",
    "\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "The above results show a *White TPR* and *Black TPR* of approximately 30.1% and 35.1% respectively\n",
    "\n",
    "The above results show a *White TNR* and *Black TNR* of approximately 91.1% and 88.1% respectively\n",
    "\n",
    "The above results show a *White FPR* and *Black FPR* of approximately 8.86% and 11.9% respectively\n",
    "\n",
    "The above results show a *White FNR* and *Black FNR* of approximately 69.8% and 64.9% respectively\n",
    "\n",
    "The above results show a *White Accuracy* and *Black Accuracy* of approximately 71.8% and 66.3% respectively\n",
    "\n",
    "\n",
    "The above results show a lot of similarities with the eduML findings. \n",
    "\n",
    "**TPR:**\n",
    "\n",
    "For instance, like the eduML dataset, the results show that the White TPR is actually lower than the Black TPR, with an almost 5% difference between the two. This indicates that there may be an inherent bias in the model's performance when classifying positive instances in the White ve Black group.\n",
    "\n",
    "**TNR:**\n",
    "The White TNR is moderately higher (3.1%) than the Black TNR however, and there is comparable gaps disparity with the TPR. It does indicate some level of difference between model's performance with Black and White groups in the dataset.\n",
    "\n",
    "\n",
    "**FPR**\n",
    "One interesting finding which differs from the eduML findings is the FPR gap. The White FPR is actually a lot lower (3.1%) showing that White predictions for Income are actually less likely to get benefit of doubt for income level higher, whereas in the eduML dataset the opposite was true.\n",
    "\n",
    "**FNR**\n",
    "\n",
    "Another similarity with the eduML findings is the FNR gap. The Black FNR is  lower (3%) showing that White groups higher than the income threshold are more likely to get a false prediction of being lower than the income threshold. \n",
    "\n",
    "This shows results which are opposite from the eduML dataset which is quite interesting as White group is penalized more but the White group seems to have a higher accuracy than the Black group.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
